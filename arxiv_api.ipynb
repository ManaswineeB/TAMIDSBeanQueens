{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56b9b14f",
   "metadata": {},
   "source": [
    "## Structure\n",
    "Below is the code I used to salvage the data from Arxiv.\n",
    "You don't need to run it. The data is collected and stored in the file 'arxived.txt'. Just run the cell below and it'll store the data in the list named 'arxiv_publications'.\n",
    "## Cleanup needed\n",
    "The list it'll load will have repeated entries and it may even have some garbage data, namely some publincations listed there may be may be of someone not related to A&M. To cleanup the repeated entry I think you can make the list a set and then convert it back into a list, and that should remove repetations. To clean up the ghost entries, I don't know how I'd do that."
   ]
  },
  {
   "cell_type": "raw",
   "id": "55601db0",
   "metadata": {},
   "source": [
    "## This cell shows the code I used to collect and store the data\n",
    "import feedparser as fp\n",
    "import urllib\n",
    "import requests\n",
    "import string\n",
    "import json\n",
    "import time\n",
    "def refine_texts(text):\n",
    "    text = text.lower()\n",
    "    text = text.replace(',','')\n",
    "    for s in text:\n",
    "        if s not in string.ascii_lowercase+string.digits:\n",
    "            text = text.replace(s,' ')\n",
    "        else:\n",
    "            continue\n",
    "    return text.split()\n",
    "\n",
    "people = requests.get('https://api.library.tamu.edu/scholars-discovery/individual/n73bc0d79?fbclid=IwAR14AfAGbKtQYKRKPsaNcAdzvqQFt76bXYunrdSUMBxZXpGKC6yKxkcGQ4E').json()\n",
    "people = people['people']\n",
    "publication_data=[]\n",
    "for i in people:\n",
    "    url = 'https://api.library.tamu.edu/scholars-discovery/individual/'+i['id']\n",
    "    publication_data.append(requests.get(url).json())\n",
    "\n",
    "outfile = open('arxived.txt','r')\n",
    "arxiv_publications = json.loads(outfile.read())\n",
    "outfile.close()\n",
    "max_results = 3\n",
    "people_counter = 110\n",
    "for p in publication_data[people_counter:]:\n",
    "    if 'publications' in p.keys():\n",
    "        arxiv_url = 'http://export.arxiv.org/api/query?search_query='\n",
    "        name = refine_texts(p['name'])\n",
    "        last_name = 'au:%s'%name[0]\n",
    "        for publication in p['publications']:\n",
    "            title_url = '+AND+ti:'\n",
    "            title = refine_texts(publication['label'])\n",
    "            title_url+= title[0]\n",
    "            for j in title[1:10]:\n",
    "                title_url+= '+AND+ti:%s'%j\n",
    "            webURL = arxiv_url+last_name+title_url\n",
    "            webURL+='&max_results=%i'%max_results\n",
    "            data = urllib.request.urlopen(arxiv_url+last_name+title_url).read()\n",
    "            feed = fp.parse(data)\n",
    "            arxiv_publications = arxiv_publications + feed['entries']\n",
    "            outfile = open('arxived.txt','w')\n",
    "            outfile.write(json.dumps(arxiv_publications))\n",
    "            outfile.close()\n",
    "            for i in feed['entries']:\n",
    "                print(i['title']+'   %i\\n'%people_counter)\n",
    "            time.sleep(4)\n",
    "        people_counter+= 1\n",
    "    else:\n",
    "        people_counter+= 1\n",
    "        continue\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9845e3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('arxived.txt','r') as f:\n",
    "    arxiv_publications = json.loads(f.read())\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4600e0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Categories = {\n",
    "    \"math.AG\" : [],\n",
    "    \"math.AT\" : [],\n",
    "    \"math.AP\" : [],\n",
    "    \"math.CT\" : [],\n",
    "    \"math.CA\" : [],\n",
    "    \"math.CO\" : [],\n",
    "    \"math.AC\" : [],\n",
    "    \"math.CV\" : [],\n",
    "    \"math.DG\" : [],\n",
    "    \"math.DS\" : [],\n",
    "    \"math.FA\" : [],\n",
    "    \"math.GM\" : [],\n",
    "    \"math.GN\" : [],\n",
    "    \"math.GT\" : [],\n",
    "    \"math.GR\" : [],\n",
    "    \"math.HO\" : [],\n",
    "    \"math.IT\" : [],\n",
    "    \"math.KT\" : [],\n",
    "    \"math.LO\" : [],\n",
    "    \"math.MP\" : [],\n",
    "    \"math.MG\" : [],\n",
    "    \"math.NT\" : [],\n",
    "    \"math.NA\" : [],\n",
    "    \"math.OA\" : [],\n",
    "    \"math.OC\" : [],\n",
    "    \"math.PR\" : [],\n",
    "    \"math.QA\" : [],\n",
    "    \"math.RT\" : [],\n",
    "    \"math.RA\" : [],\n",
    "    \"math.SP\" : [],\n",
    "    \"math.ST\" : [],\n",
    "    \"math.SG\" : []\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "306be74c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Uncomputably Large Integral Points on Algebraic Plane Curves?']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "for article in arxiv_publications:\n",
    "    for i in range(len(article['tags'])):\n",
    "        if article['tags'][i]['term'] in Categories:\n",
    "            Categories[article['tags'][i]['term']].append(article['title'])\n",
    "\n",
    "#\n",
    "for cat in Categories.keys():\n",
    "    Categories[cat] = list(set(Categories[cat]))\n",
    "\n",
    "Categories['math.LO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2a005933",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'http://arxiv.org/abs/1306.5150v4',\n",
       " 'guidislink': True,\n",
       " 'link': 'http://arxiv.org/abs/1306.5150v4',\n",
       " 'updated': '2014-10-31T03:47:25Z',\n",
       " 'updated_parsed': [2014, 10, 31, 3, 47, 25, 4, 304, 0],\n",
       " 'published': '2013-06-21T14:27:29Z',\n",
       " 'published_parsed': [2013, 6, 21, 14, 27, 29, 4, 172, 0],\n",
       " 'title': 'Vakhitov-Kolokolov and energy vanishing conditions for linear\\n  instability of solitary waves in models of classical self-interacting spinor\\n  fields',\n",
       " 'title_detail': {'type': 'text/plain',\n",
       "  'language': None,\n",
       "  'base': '',\n",
       "  'value': 'Vakhitov-Kolokolov and energy vanishing conditions for linear\\n  instability of solitary waves in models of classical self-interacting spinor\\n  fields'},\n",
       " 'summary': 'We study the linear stability of localized modes in self-interacting spinor\\nfields, analyzing the spectrum of the operator corresponding to linearization\\nat solitary waves. Following the generalization of the Vakhitov--Kolokolov\\napproach, we show that the bifurcation of real eigenvalues from the origin is\\ncompletely characterized by the Vakhitov--Kolokolov condition $dQ/d\\\\omega=0$\\nand by the vanishing of the energy functional. We give the numerical data on\\nthe linear stability in the generalized Gross--Neveu model and the generalized\\nmassive Thirring model in the charge-subcritical, critical, and supercritical\\ncases, showing the agreement with the Vakhitov--Kolokolov and the energy\\nvanishing conditions.',\n",
       " 'summary_detail': {'type': 'text/plain',\n",
       "  'language': None,\n",
       "  'base': '',\n",
       "  'value': 'We study the linear stability of localized modes in self-interacting spinor\\nfields, analyzing the spectrum of the operator corresponding to linearization\\nat solitary waves. Following the generalization of the Vakhitov--Kolokolov\\napproach, we show that the bifurcation of real eigenvalues from the origin is\\ncompletely characterized by the Vakhitov--Kolokolov condition $dQ/d\\\\omega=0$\\nand by the vanishing of the energy functional. We give the numerical data on\\nthe linear stability in the generalized Gross--Neveu model and the generalized\\nmassive Thirring model in the charge-subcritical, critical, and supercritical\\ncases, showing the agreement with the Vakhitov--Kolokolov and the energy\\nvanishing conditions.'},\n",
       " 'authors': [{'name': 'Gregory Berkolaiko'},\n",
       "  {'name': 'Andrew Comech'},\n",
       "  {'name': 'Alim Sukhtayev'}],\n",
       " 'author_detail': {'name': 'Alim Sukhtayev'},\n",
       " 'author': 'Alim Sukhtayev',\n",
       " 'arxiv_comment': '17 pages. Earliner application to Dirac--Maxwell was flawed and led\\n  to incorrect conclusions',\n",
       " 'links': [{'href': 'http://arxiv.org/abs/1306.5150v4',\n",
       "   'rel': 'alternate',\n",
       "   'type': 'text/html'},\n",
       "  {'title': 'pdf',\n",
       "   'href': 'http://arxiv.org/pdf/1306.5150v4',\n",
       "   'rel': 'related',\n",
       "   'type': 'application/pdf'}],\n",
       " 'arxiv_primary_category': {'term': 'math-ph',\n",
       "  'scheme': 'http://arxiv.org/schemas/atom'},\n",
       " 'tags': [{'term': 'math-ph',\n",
       "   'scheme': 'http://arxiv.org/schemas/atom',\n",
       "   'label': None},\n",
       "  {'term': 'math.AP',\n",
       "   'scheme': 'http://arxiv.org/schemas/atom',\n",
       "   'label': None},\n",
       "  {'term': 'math.MP',\n",
       "   'scheme': 'http://arxiv.org/schemas/atom',\n",
       "   'label': None},\n",
       "  {'term': 'nlin.PS',\n",
       "   'scheme': 'http://arxiv.org/schemas/atom',\n",
       "   'label': None},\n",
       "  {'term': '35B35, 35C08, 35Q41, 37K40, 81Q05, 81Q12',\n",
       "   'scheme': 'http://arxiv.org/schemas/atom',\n",
       "   'label': None}]}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arxiv_publications[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "82b4788f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def refine_texts(text):\n",
    "    text = text.lower()\n",
    "    text = text.replace(',','')\n",
    "    for s in text:\n",
    "        if s not in string.ascii_lowercase+string.digits:\n",
    "            text = text.replace(s,' ')\n",
    "        else:\n",
    "            continue\n",
    "    return text\n",
    "\n",
    "vizfile = open('vizfile.ris','w')\n",
    "for article in arxiv_publications:\n",
    "    vizfile.write('\\nTY  - JOUR')\n",
    "    Author = refine_texts(article['author'])\n",
    "    vizfile.write('\\nAU  - %s'%Author)\n",
    "    vizfile.write('\\nPY  - %s'%article['published'][:4])\n",
    "    Title = refine_texts(article['title'])\n",
    "    vizfile.write('\\nTI  - %s'%Title)\n",
    "    for tags in article['tags']:\n",
    "        if tags['term'] in Categories.keys():\n",
    "            vizfile.write('\\nKW  - %s'%tags['term'])\n",
    "        else:\n",
    "            continue\n",
    "    vizfile.write('\\nER  - \\n')\n",
    "\n",
    "vizfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bb200e04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'コ'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f61496",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
